{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kashimmirza/responsive-login-form/blob/master/cse498R2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBvHf03ikaNm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWM-OWj9kgdg",
        "outputId": "61a214f3-ae35-4188-c4f0-cca517773ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\n",
            "1065476096/1065471431 [==============================] - 10s 0us/step\n",
            "1065484288/1065471431 [==============================] - 10s 0us/step\n",
            "Downloading data from https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\n",
            "1045168128/1045162547 [==============================] - 11s 0us/step\n",
            "1045176320/1045162547 [==============================] - 11s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Download url of normal CT scans.\n",
        "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"CT-0.zip\")\n",
        "keras.utils.get_file(filename, url)\n",
        "\n",
        "# Download url of abnormal CT scans.\n",
        "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"CT-23.zip\")\n",
        "keras.utils.get_file(filename, url)\n",
        "\n",
        "# Make a directory to store the data.\n",
        "os.makedirs(\"MosMedData\")\n",
        "\n",
        "# Unzip data in the newly created directory.\n",
        "with zipfile.ZipFile(\"CT-0.zip\", \"r\") as z_fp:\n",
        "    z_fp.extractall(\"./MosMedData/\")\n",
        "\n",
        "with zipfile.ZipFile(\"CT-23.zip\", \"r\") as z_fp:\n",
        "    z_fp.extractall(\"./MosMedData/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eALi7L4PkqAA"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "\n",
        "from scipy import ndimage\n",
        "\n",
        "\n",
        "def read_nifti_file(filepath):\n",
        "    \"\"\"Read and load volume\"\"\"\n",
        "    # Read file\n",
        "    scan = nib.load(filepath)\n",
        "    # Get raw data\n",
        "    scan = scan.get_fdata()\n",
        "    return scan\n",
        "\n",
        "\n",
        "def normalize(volume):\n",
        "    \"\"\"Normalize the volume\"\"\"\n",
        "    min = -1000\n",
        "    max = 400\n",
        "    volume[volume < min] = min\n",
        "    volume[volume > max] = max\n",
        "    volume = (volume - min) / (max - min)\n",
        "    volume = volume.astype(\"float32\")\n",
        "    return volume\n",
        "\n",
        "\n",
        "def resize_volume(img):\n",
        "    \"\"\"Resize across z-axis\"\"\"\n",
        "    # Set the desired depth\n",
        "    desired_depth = 64\n",
        "    desired_width = 128\n",
        "    desired_height = 128\n",
        "    # Get current depth\n",
        "    current_depth = img.shape[-1]\n",
        "    current_width = img.shape[0]\n",
        "    current_height = img.shape[1]\n",
        "    # Compute depth factor\n",
        "    depth = current_depth / desired_depth\n",
        "    width = current_width / desired_width\n",
        "    height = current_height / desired_height\n",
        "    depth_factor = 1 / depth\n",
        "    width_factor = 1 / width\n",
        "    height_factor = 1 / height\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(img, 90, reshape=False)\n",
        "    # Resize across z-axis\n",
        "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
        "    return img\n",
        "\n",
        "\n",
        "def process_scan(path):\n",
        "    \"\"\"Read and resize volume\"\"\"\n",
        "    # Read scan\n",
        "    volume = read_nifti_file(path)\n",
        "    # Normalize\n",
        "    volume = normalize(volume)\n",
        "    # Resize width, height and depth\n",
        "    volume = resize_volume(volume)\n",
        "    return volume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbxKgHIgku3V",
        "outputId": "1ac4f33f-a4b2-4c77-df84-d42f83952d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CT scans with normal lung tissue: 100\n",
            "CT scans with abnormal lung tissue: 100\n"
          ]
        }
      ],
      "source": [
        "# Folder \"CT-0\" consist of CT scans having normal lung tissue,\n",
        "# no CT-signs of viral pneumonia.\n",
        "normal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), \"MosMedData/CT-0\", x)\n",
        "    for x in os.listdir(\"MosMedData/CT-0\")\n",
        "]\n",
        "# Folder \"CT-23\" consist of CT scans having several ground-glass opacifications,\n",
        "# involvement of lung parenchyma.\n",
        "abnormal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), \"MosMedData/CT-23\", x)\n",
        "    for x in os.listdir(\"MosMedData/CT-23\")\n",
        "]\n",
        "\n",
        "print(\"CT scans with normal lung tissue: \" + str(len(normal_scan_paths)))\n",
        "print(\"CT scans with abnormal lung tissue: \" + str(len(abnormal_scan_paths)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cMn348q2kzcV",
        "outputId": "d0dc9a57-3325-4e26-9ed0-c66b7db4d68e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in train and validation are 140 and 60.\n"
          ]
        }
      ],
      "source": [
        "# Read and process the scans.\n",
        "# Each scan is resized across height, width, and depth and rescaled.\n",
        "abnormal_scans = np.array([process_scan(path) for path in abnormal_scan_paths])\n",
        "normal_scans = np.array([process_scan(path) for path in normal_scan_paths])\n",
        "\n",
        "# For the CT scans having presence of viral pneumonia\n",
        "# assign 1, for the normal ones assign 0.\n",
        "abnormal_labels = np.array([1 for _ in range(len(abnormal_scans))])\n",
        "normal_labels = np.array([0 for _ in range(len(normal_scans))])\n",
        "\n",
        "# Split data in the ratio 70-30 for training and validation.\n",
        "x_train = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)\n",
        "y_train = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)\n",
        "x_val = np.concatenate((abnormal_scans[70:], normal_scans[70:]), axis=0)\n",
        "y_val = np.concatenate((abnormal_labels[70:], normal_labels[70:]), axis=0)\n",
        "print(\n",
        "    \"Number of samples in train and validation are %d and %d.\"\n",
        "    % (x_train.shape[0], x_val.shape[0])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4N4HgV9k3ld"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "from scipy import ndimage\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def rotate(volume):\n",
        "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
        "\n",
        "    def scipy_rotate(volume):\n",
        "        # define some rotation angles\n",
        "        angles = [-20, -10, -5, 5, 10, 20]\n",
        "        # pick angles at random\n",
        "        angle = random.choice(angles)\n",
        "        # rotate volume\n",
        "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
        "        volume[volume < 0] = 0\n",
        "        volume[volume > 1] = 1\n",
        "        return volume\n",
        "\n",
        "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
        "    return augmented_volume\n",
        "\n",
        "\n",
        "def train_preprocessing(volume, label):\n",
        "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
        "    # Rotate volume\n",
        "    volume = rotate(volume)\n",
        "    volume = tf.expand_dims(volume, axis=3)\n",
        "    return volume, label\n",
        "\n",
        "\n",
        "def validation_preprocessing(volume, label):\n",
        "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
        "    volume = tf.expand_dims(volume, axis=3)\n",
        "    return volume, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-hQQL0Gk8Id"
      },
      "outputs": [],
      "source": [
        "# Define data loaders.\n",
        "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "\n",
        "batch_size = 2\n",
        "# Augment the on the fly during training.\n",
        "train_dataset = (\n",
        "    train_loader.shuffle(len(x_train))\n",
        "    .map(train_preprocessing)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(2)\n",
        ")\n",
        "# Only rescale.\n",
        "validation_dataset = (\n",
        "    validation_loader.shuffle(len(x_val))\n",
        "    .map(validation_preprocessing)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mX5opXdo_Hv"
      },
      "outputs": [],
      "source": [
        "print('train_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCDQLBjalyWm"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import pickle\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "import os\n",
        "'''\n",
        "\n",
        "print(os.listdir(\"images/\"))\n",
        "\n",
        "SIZE = 512 \n",
        "\n",
        "train_images = []\n",
        "\n",
        "for directory_path in glob.glob(\"images/train_images\"):\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.tif\")):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
        "        img = cv2.resize(img, (SIZE, SIZE))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        train_images.append(img)\n",
        "        #train_labels.append(label)\n",
        "        \n",
        "train_images = np.array(train_images)\n",
        "\n",
        "train_masks = [] \n",
        "for directory_path in glob.glob(\"images/train_masks\"):\n",
        "    for mask_path in glob.glob(os.path.join(directory_path, \"*.tif\")):\n",
        "        mask = cv2.imread(mask_path, 0)       \n",
        "        mask = cv2.resize(mask, (SIZE, SIZE))\n",
        "        #mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)\n",
        "        train_masks.append(mask)\n",
        "        #train_labels.append(label)\n",
        "        \n",
        "train_masks = np.array(train_masks)\n",
        "\n",
        "X_train = train_images\n",
        "y_train = train_masks\n",
        "y_train = np.expand_dims(y_train, axis=3)\n",
        "'''\n",
        "SIZE = 128\n",
        "\n",
        "\n",
        "activation = 'sigmoid'\n",
        "feature_extractor = Sequential()\n",
        "inputs = keras.Input((128, 128, 64, 1))\n",
        "inputs = keras.Input((128, 128, 64, 1))\n",
        "#feature_extractor.add(Conv3D(64, 3, activation = activation, padding = 'same')(inputs)\n",
        "#feature_extractor.add(MaxPool3D(pool_size=2))\n",
        "#feature_extractor.add(Conv3D(32, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
        "x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.MaxPool3D(pool_size=2)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPool3D(pool_size=2)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPool3D(pool_size=2)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPool3D(pool_size=2)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.GlobalAveragePooling3D()(x)\n",
        "x = layers.Dense(units=512, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "#feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
        "#feature_extractor.add(BatchNormalization())\n",
        "#\n",
        "#feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
        "#feature_extractor.add(BatchNormalization())\n",
        "#feature_extractor.add(MaxPooling2D())\n",
        "#feature_extractor.add(Flatten())\n",
        "\n",
        "X = x.predict(x_train)\n",
        "\n",
        "X = X.reshape(-1, X.shape[3])\n",
        "\n",
        "Y = y_train.reshape(-1)\n",
        "\n",
        "dataset = pd.DataFrame(X)\n",
        "dataset['Label'] = Y\n",
        "print(dataset['Label'].unique())\n",
        "print(dataset['Label'].value_counts())\n",
        "\n",
        "##If we do not want to include pixels with value 0 \n",
        "##e.g. Sometimes unlabeled pixels may be given a value 0.\n",
        "dataset = dataset[dataset['Label'] != 0]\n",
        "\n",
        "X_for_RF = dataset.drop(labels = ['Label'], axis=1)\n",
        "Y_for_RF = dataset['Label']\n",
        "\n",
        "#RANDOM FOREST\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "# Ravel Y to pass 1d array instead of column vector\n",
        "model.fit(X_for_RF, Y_for_RF) #For sklearn no one hot encoding\n",
        "\n",
        "\n",
        "filename = 'RF_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        "\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "\n",
        "'''\n",
        "#READ EXTERNAL IMAGE...\n",
        "test_img = cv2.imread('images/test_images/Sandstone_Versa0360.tif', cv2.IMREAD_COLOR)       \n",
        "test_img = cv2.resize(test_img, (SIZE, SIZE))\n",
        "test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)\n",
        "test_img = np.expand_dims(test_img, axis=0)\n",
        "\n",
        "#predict_image = np.expand_dims(X_train[8,:,:,:], axis=0)\n",
        "X_test_feature = feature_extractor.predict(test_img)\n",
        "X_test_feature = X_test_feature.reshape(-1, X_test_feature.shape[3])\n",
        "\n",
        "prediction = loaded_model.predict(X_test_feature)\n",
        "\n",
        "prediction_image = prediction.reshape(mask.shape)\n",
        "plt.imshow(prediction_image, cmap='gray')\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC1SNJDXltgu"
      },
      "outputs": [],
      "source": [
        "# Load best weights.\n",
        "model.load_weights(\"3d_image_classification.h5\")\n",
        "prediction = model.predict(np.expand_dims(x_val[0], axis=0))[0]\n",
        "scores = [1 - prediction[0], prediction[0]]\n",
        "\n",
        "class_names = [\"normal\", \"abnormal\"]\n",
        "for score, name in zip(scores, class_names):\n",
        "    print(\n",
        "        \"This model is %.2f percent confident that CT scan is %s\"\n",
        "        % ((100 * score), name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atZuP82jlDvt"
      },
      "outputs": [],
      "source": [
        "def get_model(width=128, height=128, depth=64):\n",
        "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
        "\n",
        "    inputs = keras.Input((width, height, depth, 1))\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling3D()(x)\n",
        "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    # Define the model.\n",
        "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# Build model.\n",
        "model = Sequential()\n",
        "model = get_model(width=128, height=128, depth=64)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3HUmWrE2w-N"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "OidB_CR2IH0E",
        "outputId": "c2fd0c58-45de-4072-ecc7-497ff423f61b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f8db6982afcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#X = X.reshape(-1, X.shape[3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "X = model.predict(x_train)\n",
        "tf.shape(X)\n",
        "\n",
        "#X = X.reshape(-1, X.shape[3])\n",
        "\n",
        "#Y = y_train.reshape(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU2nDQR0JBPT"
      },
      "outputs": [],
      "source": [
        "dataset = pd.DataFrame(X)\n",
        "dataset['Label'] = Y\n",
        "print(dataset['Label'].unique())\n",
        "print(dataset['Label'].value_counts())\n",
        "\n",
        "##If we do not want to include pixels with value 0 \n",
        "##e.g. Sometimes unlabeled pixels may be given a value 0.\n",
        "dataset = dataset[dataset['Label'] != 0]\n",
        "\n",
        "X_for_RF = dataset.drop(labels = ['Label'], axis=1)\n",
        "Y_for_RF = dataset['Label']\n",
        "\n",
        "#RANDOM FOREST\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
        "\n",
        "# Train the model on training data\n",
        "# Ravel Y to pass 1d array instead of column vector\n",
        "model.fit(X_for_RF, Y_for_RF) #For sklearn no one hot encoding\n",
        "\n",
        "\n",
        "filename = 'RF_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        "\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "\n",
        "'''\n",
        "#READ EXTERNAL IMAGE...\n",
        "test_img = cv2.imread('images/test_images/Sandstone_Versa0360.tif', cv2.IMREAD_COLOR)       \n",
        "test_img = cv2.resize(test_img, (SIZE, SIZE))\n",
        "test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)\n",
        "test_img = np.expand_dims(test_img, axis=0)\n",
        "\n",
        "#predict_image = np.expand_dims(X_train[8,:,:,:], axis=0)\n",
        "X_test_feature = feature_extractor.predict(test_img)\n",
        "X_test_feature = X_test_feature.reshape(-1, X_test_feature.shape[3])\n",
        "\n",
        "prediction = loaded_model.predict(X_test_feature)\n",
        "\n",
        "prediction_image = prediction.reshape(mask.shape)\n",
        "plt.imshow(prediction_image, cmap='gray')\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzS4kmcKlPum"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, metric in enumerate([\"acc\", \"loss\"]):\n",
        "    ax[i].plot(model.history.history[metric])\n",
        "    ax[i].plot(model.history.history[\"val_\" + metric])\n",
        "    ax[i].set_title(\"Model {}\".format(metric))\n",
        "    ax[i].set_xlabel(\"epochs\")\n",
        "    ax[i].set_ylabel(metric)\n",
        "    ax[i].legend([\"train\", \"val\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cn6XQKwlUL-"
      },
      "outputs": [],
      "source": [
        "# Load best weights.\n",
        "model.load_weights(\"3d_image_classification.h5\")\n",
        "prediction = model.predict(np.expand_dims(x_val[0], axis=0))[0]\n",
        "scores = [1 - prediction[0], prediction[0]]\n",
        "\n",
        "class_names = [\"normal\", \"abnormal\"]\n",
        "for score, name in zip(scores, class_names):\n",
        "    print(\n",
        "        \"This model is %.2f percent confident that CT scan is %s\"\n",
        "        % ((100 * score), name)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjF8mfiplJJ1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cse498R2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMd2vnvj10QX3VMJ5PI3UGc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}